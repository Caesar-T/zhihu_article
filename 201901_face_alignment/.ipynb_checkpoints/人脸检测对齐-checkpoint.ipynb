{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from PIL import Image,ImageDraw\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition  # install from https://github.com/ageitgey/face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-886df5449d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "img_name = './img/Aishwarya_Rai_0001.jpg'\n",
    "img_name = './img/Britney_Spears_0004.jpg'\n",
    "\n",
    "image_array = cv2.imread(img_name)\n",
    "image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "Image.fromarray(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人脸检测\n",
    "使用[face_recognition api](https://github.com/ageitgey/face_recognition)检测人脸的关键点， model=\"large\"时返回68个关键点， model=\"small\"时返回5个关键点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks_list = face_recognition.face_landmarks(image_array, model=\"large\")\n",
    "face_landmarks_dict = face_landmarks_list[0]\n",
    "print(face_landmarks_dict, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义人脸关键点可视化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_landmark(image_array, landmarks):\n",
    "    \"\"\" plot landmarks on image\n",
    "    :param image_array: numpy array of a single image\n",
    "    :param landmarks: dict of landmarks for facial parts as keys and tuple of coordinates as values\n",
    "    :return: plots of images with landmarks on\n",
    "    \"\"\"\n",
    "    origin_img = Image.fromarray(image_array)\n",
    "    draw = ImageDraw.Draw(origin_img)\n",
    "    for facial_feature in landmarks.keys():\n",
    "        draw.point(landmarks[facial_feature])\n",
    "    imshow(origin_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化人脸关键点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_landmark(image_array=image_array,landmarks=face_landmarks_dict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人脸对齐\n",
    "### 人脸旋转对齐\n",
    "人脸对齐思路：\n",
    "* 分别计算左、右眼中心坐标\n",
    "* 计算左右眼中心坐标与水平方向的夹角θ\n",
    "* 计算左右两眼整体中心坐标\n",
    "* 以左右两眼整体中心坐标为基点，将图片array逆时针旋转θ    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下定义了人脸对齐函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_face(image_array, landmarks):\n",
    "    \"\"\" align faces according to eyes position\n",
    "    :param image_array: numpy array of a single image\n",
    "    :param landmarks: dict of landmarks for facial parts as keys and tuple of coordinates as values\n",
    "    :return:\n",
    "    rotated_img:  numpy array of aligned image\n",
    "    eye_center: tuple of coordinates for eye center\n",
    "    angle: degrees of rotation\n",
    "    \"\"\"\n",
    "    # get list landmarks of left and right eye\n",
    "    left_eye = landmarks['left_eye']\n",
    "    right_eye = landmarks['right_eye']\n",
    "    # calculate the mean point of landmarks of left and right eye\n",
    "    left_eye_center = np.mean(left_eye, axis=0).astype(\"int\")\n",
    "    right_eye_center = np.mean(right_eye, axis=0).astype(\"int\")\n",
    "    # compute the angle between the eye centroids\n",
    "    dy = right_eye_center[1] - left_eye_center[1]\n",
    "    dx = right_eye_center[0] - left_eye_center[0]\n",
    "    # compute angle between the line of 2 centeroids and the horizontal line\n",
    "    angle = math.atan2(dy, dx) * 180. / math.pi\n",
    "    # calculate the center of 2 eyes\n",
    "    eye_center = ((left_eye_center[0] + right_eye_center[0]) // 2,\n",
    "                  (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "    # at the eye_center, rotate the image by the angle\n",
    "    rotate_matrix = cv2.getRotationMatrix2D(eye_center, angle, scale=1)\n",
    "    rotated_img = cv2.warpAffine(image_array, rotate_matrix, (image_array.shape[0], image_array.shape[1]))\n",
    "    return rotated_img, eye_center, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据眼睛位置旋转整个图片，达到人脸对齐的目的。下图可以看出，旋转后图片（右图）中的人脸一对齐，双眼在水平方向上。align_face函数输出的eye_center, angle会在章节4.2张使用到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_face, eye_center, angle = align_face(image_array=image_array, landmarks=face_landmarks_dict)\n",
    "Image.fromarray(np.hstack((image_array,aligned_face)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人脸关键点旋转\n",
    "图片旋转后，图中的landmark坐标也要相应旋转，这样landmark才能匹配旋转后的图片。landmark旋转前的效果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_landmark(image_array=aligned_face,landmarks=face_landmarks_dict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义旋转图片中坐标的函数，由于图片和普通坐标系的原点不同，两者坐标点的旋转方式略有出入，图片坐标旋转涉及y坐标在图片坐标系和普通坐标系之间的变换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(origin, point, angle, row):\n",
    "    \"\"\" rotate coordinates in image coordinate system\n",
    "    :param origin: tuple of coordinates,the rotation center\n",
    "    :param point: tuple of coordinates, points to rotate\n",
    "    :param angle: degrees of rotation\n",
    "    :param row: row size of the image\n",
    "    :return: rotated coordinates of point\n",
    "    \"\"\"\n",
    "    x1, y1 = point\n",
    "    x2, y2 = origin\n",
    "    y1 = row - y1\n",
    "    y2 = row - y2\n",
    "    angle = math.radians(angle)\n",
    "    x = x2 + math.cos(angle) * (x1 - x2) - math.sin(angle) * (y1 - y2)\n",
    "    y = y2 + math.sin(angle) * (x1 - x2) + math.cos(angle) * (y1 - y2)\n",
    "    y = row - y\n",
    "    return int(x), int(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义旋转图片中landmark的函数，以人脸双眼中心为基点，将每个人脸关键点逆时针旋转θ，该θ角度是人脸对齐的旋转角度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_landmarks(landmarks, eye_center, angle, row):\n",
    "    \"\"\" rotate landmarks to fit the aligned face\n",
    "    :param landmarks: dict of landmarks for facial parts as keys and tuple of coordinates as values\n",
    "    :param eye_center: tuple of coordinates for eye center\n",
    "    :param angle: degrees of rotation\n",
    "    :param row: row size of the image\n",
    "    :return: rotated_landmarks with the same structure with landmarks, but different values\n",
    "    \"\"\"\n",
    "    rotated_landmarks = defaultdict(list)\n",
    "    for facial_feature in landmarks.keys():\n",
    "        for landmark in landmarks[facial_feature]:\n",
    "            rotated_landmark = rotate(origin=eye_center, point=landmark, angle=angle, row=row)\n",
    "            rotated_landmarks[facial_feature].append(rotated_landmark)\n",
    "    return rotated_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下旋转所有人脸关键点，并可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_landmarks = rotate_landmarks(landmarks=face_landmarks_dict,\n",
    "                                         eye_center=eye_center, angle=angle, row=image_array.shape[0])\n",
    "visualize_landmark(image_array=aligned_face,landmarks=rotated_landmarks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人脸裁剪\n",
    "通常，人脸对齐后会根据landmark裁剪人脸到固定尺寸，再feed近卷积网络。此处裁剪的思路为：\n",
    "* 水平方向以最靠左和最靠右的landmark的中点为裁剪后图片的中心点\n",
    "* 垂直方向上分为三部分\n",
    "    * 中部：两眼landmark中心到嘴巴landmark中心的像素距离，占垂直方向的35%\n",
    "    * 底部：占垂直方向的35%\n",
    "    * 顶部：占垂直方向的30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义裁剪函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corp_face(image_array, size, landmarks):\n",
    "    \"\"\" crop face according to eye,mouth and chin position\n",
    "    :param image_array: numpy array of a single image\n",
    "    :param size: single int value, w and h to resize cropped images\n",
    "    :param landmarks: dict of landmarks for facial parts as keys and tuple of coordinates as values\n",
    "    :return:\n",
    "    cropped_img: numpy array of cropped and resized image\n",
    "    \"\"\"\n",
    "\n",
    "    eye_landmark = np.concatenate([np.array(landmarks['left_eye']),\n",
    "                                   np.array(landmarks['right_eye'])])\n",
    "    eye_center = np.mean(eye_landmark, axis=0).astype(\"int\")\n",
    "    lip_landmark = np.concatenate([np.array(landmarks['top_lip']),\n",
    "                                   np.array(landmarks['bottom_lip'])])\n",
    "    lip_center = np.mean(lip_landmark, axis=0).astype(\"int\")\n",
    "    mid_part = lip_center[1] - eye_center[1]\n",
    "    top = eye_center[1] - mid_part * 30 / 35\n",
    "    bottom = lip_center[1] + mid_part\n",
    "\n",
    "    w = h = bottom - top\n",
    "    x_min = np.min(landmarks['chin'], axis=0)[0]\n",
    "    x_max = np.max(landmarks['chin'], axis=0)[0]\n",
    "    x_center = (x_max - x_min) / 2 + x_min\n",
    "    left, right = (x_center - w / 2, x_center + w / 2)\n",
    "\n",
    "    pil_img = Image.fromarray(image_array)\n",
    "    left, top, right, bottom = [int(i) for i in [left, top, right, bottom]]\n",
    "    cropped_img = pil_img.crop((left, top, right, bottom))\n",
    "    cropped_img = np.array(cropped_img)\n",
    "    resized_img = cv2.resize(cropped_img, (size, size))\n",
    "    return resized_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人脸裁剪和resize后，大小变成了140 * 140。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corp_face' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d1d21a5b87f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_face\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcorp_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maligned_face\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m140\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrotated_landmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_face\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_face\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corp_face' is not defined"
     ]
    }
   ],
   "source": [
    "final_face= corp_face(image_array=aligned_face, size=140, landmarks=rotated_landmarks)\n",
    "print(final_face.shape)\n",
    "Image.fromarray(final_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
